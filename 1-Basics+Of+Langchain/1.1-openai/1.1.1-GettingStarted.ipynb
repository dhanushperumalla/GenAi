{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['GOOGLE_API_KEY']=os.getenv(\"GOOGLE_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='models/gemini-1.5-flash' client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001EB6A12B5E0> async_client=<google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsyncClient object at 0x000001EB0DAA5690> default_metadata=()\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm=ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Generative AI: The AI that Creates\n",
      "\n",
      "Generative AI is a type of artificial intelligence that focuses on **creating new content**. Unlike traditional AI that analyzes existing data, generative AI uses algorithms to learn patterns and structures from the data it's trained on, and then **generates new, original outputs**. \n",
      "\n",
      "Think of it like this:\n",
      "\n",
      "* **Traditional AI:**  Analyzes a photo of a cat and tells you it's a cat.\n",
      "* **Generative AI:** Creates a new, realistic photo of a cat that doesn't exist in the real world.\n",
      "\n",
      "Here are some key characteristics of generative AI:\n",
      "\n",
      "* **Learning from data:**  It needs vast amounts of data to learn patterns and structures.\n",
      "* **Creating novel content:**  It produces original outputs, not just copies of existing data.\n",
      "* **Variety of applications:** It can be used for text, images, audio, video, code, and more.\n",
      "\n",
      "**Examples of Generative AI:**\n",
      "\n",
      "* **Text Generation:** ChatGPT, Bard, and other language models can write stories, poems, articles, and even code.\n",
      "* **Image Generation:** DALL-E 2, Midjourney, and Stable Diffusion can create realistic images from text descriptions.\n",
      "* **Audio Generation:**  Jukebox can generate music in different styles and genres.\n",
      "* **Video Generation:**  Generative AI can create realistic videos, even with human-like movements.\n",
      "\n",
      "**Potential Benefits of Generative AI:**\n",
      "\n",
      "* **Creativity and innovation:**  It can help artists, writers, and other creators explore new ideas.\n",
      "* **Efficiency and productivity:**  It can automate tasks like writing, generating images, and creating code.\n",
      "* **Personalized experiences:**  It can create customized content for individual users.\n",
      "\n",
      "**Potential Challenges of Generative AI:**\n",
      "\n",
      "* **Ethical concerns:**  It raises questions about copyright, authenticity, and potential misuse.\n",
      "* **Bias and misinformation:**  The output of generative AI can reflect biases present in the training data.\n",
      "* **Job displacement:**  It might automate certain tasks, potentially impacting certain job roles.\n",
      "\n",
      "Generative AI is a rapidly evolving field with immense potential. It's important to understand its capabilities, limitations, and ethical implications as it continues to shape our world.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert AI Engineer. Provide me answers based on the questions')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Langsmith: Your AI Model's Personal Trainer\n",
      "\n",
      "Langsmith is a powerful tool that helps you **build and improve your large language models (LLMs)**. It's essentially a **\"gym\" for your AI models**, providing a suite of features to train, evaluate, and refine them for specific tasks. \n",
      "\n",
      "Here's a breakdown of what Langsmith offers:\n",
      "\n",
      "**1. Data-Centric Approach:**\n",
      "\n",
      "* **Data Management:** Langsmith focuses on managing and organizing your training data effectively. You can **upload, label, and annotate data** directly within the platform, making it easier to create high-quality datasets.\n",
      "* **Data Versioning:** Track changes to your data and roll back to previous versions, ensuring reproducibility and accountability.\n",
      "* **Data Exploration & Analysis:** Visualize your data to understand its distribution and identify potential biases or issues.\n",
      "\n",
      "**2. Model Training & Evaluation:**\n",
      "\n",
      "* **Fine-tuning:** Langsmith allows you to fine-tune pre-trained LLMs on your specific data, tailoring them to your desired task.\n",
      "* **Automated Evaluation:** It provides various metrics and tools to assess your model's performance on different tasks, helping you understand its strengths and weaknesses.\n",
      "* **Interactive Debugging:** Identify and resolve issues in your model's training process through interactive visualizations and logs.\n",
      "\n",
      "**3. Model Deployment & Monitoring:**\n",
      "\n",
      "* **Easy Deployment:** Langsmith integrates with popular cloud platforms, enabling seamless model deployment and scaling.\n",
      "* **Performance Monitoring:** Track your model's performance in real-world scenarios and identify potential degradation over time.\n",
      "* **Model Governance:** Control access and usage of your models, ensuring responsible AI practices.\n",
      "\n",
      "**4. Collaboration & Teamwork:**\n",
      "\n",
      "* **Shared Workspaces:** Collaborate with team members on projects, share data, and manage access controls.\n",
      "* **Version Control:** Track changes to your data, models, and code, ensuring transparency and reproducibility.\n",
      "* **Communication & Feedback:** Discuss ideas, share insights, and provide feedback within the platform.\n",
      "\n",
      "**Benefits of using Langsmith:**\n",
      "\n",
      "* **Faster Model Development:** Streamline your workflow and accelerate the development of high-performing LLMs.\n",
      "* **Improved Model Accuracy:** Build models that are better aligned with your specific needs and data.\n",
      "* **Enhanced Collaboration:** Work effectively with your team to build and deploy AI models.\n",
      "* **Responsible AI:** Implement best practices for data management, model governance, and responsible AI development.\n",
      "\n",
      "**Overall, Langsmith empowers data scientists, engineers, and researchers to build, train, and manage LLMs more efficiently and effectively.** It's a valuable tool for anyone looking to harness the power of AI for specific tasks and applications.\n",
      "\n",
      "**Note:** Langsmith is currently in beta, but it's gaining popularity as a powerful tool for building and improving LLMs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Langsmith: Your LLM Development Companion\n",
      "\n",
      "Langsmith is a powerful tool designed to streamline and enhance the development process for Large Language Models (LLMs). It provides a comprehensive platform that encompasses:\n",
      "\n",
      "**1. Data Management:**\n",
      "\n",
      "* **Data Versioning:** Track changes to your datasets, enabling you to easily revert to previous versions and understand the impact of modifications.\n",
      "* **Data Exploration:** Explore your data with interactive visualizations and powerful filtering capabilities, gaining deeper insights into its structure and content.\n",
      "* **Data Augmentation:** Generate synthetic data that mirrors your real-world data, expanding your training dataset and improving model robustness.\n",
      "\n",
      "**2. Model Training & Evaluation:**\n",
      "\n",
      "* **Model Training:** Train your LLMs efficiently with integrated tools that handle data preparation, model selection, and hyperparameter tuning.\n",
      "* **Model Evaluation:** Evaluate your model's performance using various metrics and visualizations, providing a clear understanding of its strengths and weaknesses.\n",
      "* **Model Comparison:** Compare different models side-by-side, allowing you to identify the best candidate for your specific use case.\n",
      "\n",
      "**3. Prompt Engineering & Testing:**\n",
      "\n",
      "* **Prompt Library:** Create and organize your prompts, allowing for easy reuse and collaboration within your team.\n",
      "* **Prompt Testing:** Test your prompts against different data sets and model configurations, ensuring their effectiveness and consistency.\n",
      "* **Prompt Analysis:** Understand your prompt's behavior with detailed analysis of its impact on the LLM's output.\n",
      "\n",
      "**4. Collaboration & Version Control:**\n",
      "\n",
      "* **Shared Workspace:** Collaborate with your team on data, models, and prompts in a shared workspace, fostering efficient communication and development.\n",
      "* **Version Control:** Track changes to your data, models, and prompts, enabling seamless rollbacks and audit trails.\n",
      "\n",
      "**5. Integration & Deployment:**\n",
      "\n",
      "* **API Integration:** Easily integrate your trained models into your applications using Langsmith's robust API.\n",
      "* **Deployment Options:** Deploy your models to various environments, including on-premise, cloud-based, or serverless platforms.\n",
      "\n",
      "**Benefits of Using Langsmith:**\n",
      "\n",
      "* **Increased Efficiency:** Streamline your LLM development workflow with automated tasks and integrated tools.\n",
      "* **Improved Collaboration:** Foster efficient collaboration within your team through shared workspaces and version control.\n",
      "* **Enhanced Model Performance:** Train and evaluate your models effectively, leading to improved accuracy and reliability.\n",
      "* **Reduced Development Costs:** Optimize your development process, minimizing time and resources spent.\n",
      "* **Simplified Deployment:** Easily deploy your models to various environments, enabling rapid integration into your applications.\n",
      "\n",
      "**Overall, Langsmith offers a comprehensive solution for LLM development, enabling developers to build, train, evaluate, and deploy high-quality models efficiently and effectively.**\n",
      "\n",
      "**Note:** Langsmith is a relatively new platform, and its features and functionality are constantly evolving. For the most up-to-date information, it's recommended to visit their official website or documentation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
